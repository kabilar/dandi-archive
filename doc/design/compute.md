## Goals

## Use case - Current computation
Checksum of assets

## Use case 1 - Pipeline service
Upon upload, dendro automate running analysis
Consolidate workflows for processing

## Use case 2 - Connect to compute engines
Extend dendro
Scale
Specific to infrastructure or generic form
Constrain service
NSF Neuroscience Gateway
MIT HPC
S3 interface on HPCs
minio
S3fs
globus(compute)
Brainlife
Globus Compute
Job scheduler
Triggered by data modifications on archive
Read and write to archive
Serverless architectures
API for compute
Leverage existing tooling
RabbitMQ, Celery
SLURM
How would analysis be triggered?
Manual or automated
Parameters
User defined?
ML-defined?
Benchmark, optimize
Analysis methods

## Requirements


